{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30d4bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, Sampler\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import math\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ebb745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a599de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andesite  :\t43802\n",
      "Basalt    :\t26810\n",
      "Etc       :\t15935\n",
      "Gneiss    :\t73914\n",
      "Granite   :\t92923\n",
      "Mud_Sandstone:\t89467\n",
      "Weathered_Rock:\t37169\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for index, folder_name in enumerate(glob.glob(r'C:\\Users\\user\\Downloads\\open\\open\\train\\*')):\n",
    "    plt.bar(index, len(glob.glob(f'{folder_name}\\\\*')), label=os.path.basename(folder_name))\n",
    "    print(f\"{os.path.basename(folder_name):<10s}:\\t{len(glob.glob(f'{folder_name}\\\\*'))}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b98457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.epoch = 60\n",
    "\n",
    "        self.image_size = (224, 224)\n",
    "        self.lr = 0.00005\n",
    "        self.weight_decay = 0.001\n",
    "    \n",
    "        self.train_data_dir = r'C:\\Users\\user\\Downloads\\open\\open\\train'\n",
    "        self.test_data_dir = r'C:\\Users\\user\\Downloads\\open\\open\\test'\n",
    "        self.test_size = 0.2\n",
    "        self.batch_size = 36\n",
    "        self.sample_num = 8000\n",
    "\n",
    "        self.visualize_epoch = 5\n",
    "        self.visualize_save_dir = os.path.join(os.getcwd(), 'visualized_features')\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4305b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ed4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, z_i, z_j, z_label=None):\n",
    "        batch_size = z_i.size(0)\n",
    "        \n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        \n",
    "        sim_matrix = torch.matmul(z, z.T) / self.temperature\n",
    "        sim_matrix = sim_matrix - torch.max(sim_matrix, dim=1, keepdim=True)[0]\n",
    "\n",
    "        labels = z_label.repeat_interleave(2)\n",
    "        mask = torch.eq(labels.unsqueeze(0), labels.unsqueeze(1)).float().to(z_i.device)\n",
    "        mask.fill_diagonal_(0)\n",
    "\n",
    "        logits_mask = ~torch.eye(2 * batch_size, dtype=torch.bool).to(z_i.device)\n",
    "        exp_sim = torch.exp(sim_matrix) * logits_mask\n",
    "\n",
    "        log_prob = sim_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-12)\n",
    "        log_prob = log_prob * logits_mask\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / (mask.sum(dim=1) + 1e-12)\n",
    "        # loss = -loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d9319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = F.log_softmax(inputs, dim=1)\n",
    "        probs = torch.exp(log_probs)\n",
    "        targets = targets.view(-1, 1)\n",
    "\n",
    "        log_p = log_probs.gather(1, targets).squeeze(1)\n",
    "        p_t = probs.gather(1, targets).squeeze(1)\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (list, torch.Tensor)):\n",
    "                alpha_t = self.alpha[targets.squeeze()]\n",
    "            else:\n",
    "                alpha_t = self.alpha\n",
    "            loss = -alpha_t * (1 - p_t) ** self.gamma * log_p\n",
    "        else:\n",
    "            loss = -(1 - p_t) ** self.gamma * log_p\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c72a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedBatchSampler(Sampler):\n",
    "    def __init__(self, labels, batch_size):\n",
    "        self.labels = np.array(labels)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.label_to_indices = defaultdict(list)\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            self.label_to_indices[label].append(idx)\n",
    "\n",
    "        self.class_ratios = {\n",
    "            label: len(idxs) / len(self.labels)\n",
    "            for label, idxs in self.label_to_indices.items()\n",
    "        }\n",
    "\n",
    "        self.label_queues = {\n",
    "            label: [] for label in self.label_to_indices\n",
    "        }\n",
    "\n",
    "        self._reset_label_queues()\n",
    "        self.batches = self._create_batches()\n",
    "\n",
    "    def _reset_label_queues(self):\n",
    "        for label in self.label_to_indices:\n",
    "            indices = self.label_to_indices[label]\n",
    "            random.shuffle(indices)\n",
    "            self.label_queues[label].extend(indices)\n",
    "\n",
    "    def _create_batches(self):\n",
    "        batches = []\n",
    "        current_batch = []\n",
    "\n",
    "        total_samples = len(self.labels)\n",
    "        num_batches = math.ceil(total_samples / self.batch_size)\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            batch = []\n",
    "            for label, ratio in self.class_ratios.items():\n",
    "                n_samples = int(round(ratio * self.batch_size))\n",
    "\n",
    "                # refill if empty\n",
    "                if len(self.label_queues[label]) < n_samples:\n",
    "                    remaining = self.label_to_indices[label][:]\n",
    "                    random.shuffle(remaining)\n",
    "                    self.label_queues[label].extend(remaining)\n",
    "\n",
    "                for _ in range(n_samples):\n",
    "                    if self.label_queues[label]:\n",
    "                        batch.append(self.label_queues[label].pop())\n",
    "\n",
    "            # 보정: 너무 작거나 클 경우\n",
    "            if len(batch) > self.batch_size:\n",
    "                batch = random.sample(batch, self.batch_size)\n",
    "                \n",
    "            elif len(batch) < self.batch_size:\n",
    "                # 부족하면 다른 클래스에서 추가\n",
    "                extra = self.batch_size - len(batch)\n",
    "                flat_pool = sum(self.label_queues.values(), [])\n",
    "                random.shuffle(flat_pool)\n",
    "                batch += flat_pool[:extra]\n",
    "                for idx in batch[-extra:]:\n",
    "                    label = self.labels[idx]\n",
    "                    if idx in self.label_queues[label]:\n",
    "                        self.label_queues[label].remove(idx)\n",
    "\n",
    "            batches.append(batch)\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.batches)\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfac338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_model(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(backbone, str):\n",
    "            self.backbone = timm.create_model(backbone, pretrained=True, num_classes=0)\n",
    "        elif isinstance(backbone, nn.Module):\n",
    "            self.backbone = backbone\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, 224, 224)\n",
    "            num_features = self.backbone(dummy).shape[1]\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_features, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        if return_features:\n",
    "            return self.head(features), features\n",
    "        \n",
    "        return self.head(features)\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1ddb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380020"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_list = glob.glob(rf\"{config.train_data_dir}\\*\\*\")\n",
    "len(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30eacd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_num_classes = len(glob.glob(rf\"{config.train_data_dir}\\*\"))\n",
    "_num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06cc6e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_model(\n",
       "  (backbone): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=2048, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (5): GELU(approximate='none')\n",
       "    (6): Linear(in_features=256, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _backbone = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n",
    "_backbone = torch.load('backbone.pt', weights_only=False, map_location='cpu')\n",
    "\n",
    "model = custom_model(_backbone, _num_classes).to(config.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a7dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(config.image_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.41427545, 0.40396059, 0.39235218], \n",
    "                         std=[0.17746354, 0.17282704, 0.16986775])\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize(config.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.41427545, 0.40396059, 0.39235218], \n",
    "                         std=[0.17746354, 0.17282704, 0.16986775])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c765eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, image_path_set, label_list, transform):\n",
    "        # self.image_paths = [path for path, label in image_path_set]\n",
    "        # self.labels = [label for path, label in image_path_set]\n",
    "        self.image_paths = [path for path in image_path_set]\n",
    "        self.labels = [os.path.basename(os.path.dirname(path)) for path in image_path_set]\n",
    "\n",
    "        self.label_list = label_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _image_path = self.image_paths[index]\n",
    "        _image_label = self.label_list.index(self.labels[index])\n",
    "\n",
    "        _image = Image.open(_image_path)\n",
    "        _image_1 = self.transform(_image)\n",
    "        _image_2 = self.transform(_image)\n",
    "\n",
    "        return (_image_1, _image_2), _image_label, _image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50482b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_data_factory():\n",
    "    def __init__(self, paths, sample_num, train_transform, valid_transform):\n",
    "        # self.paths = [(path, os.path.basename(os.path.dirname(path))) for path in paths]\n",
    "        self.path_dict = {}\n",
    "        for path in paths:\n",
    "            _class = os.path.basename(os.path.dirname(path))\n",
    "            if self.path_dict.get(_class) == None:\n",
    "                self.path_dict[_class] = []\n",
    "\n",
    "            self.path_dict[_class].append(path)\n",
    "\n",
    "        self.selected_items = {_label: random.choices(_path_list, k=min(len(_path_list), sample_num)) for _label, _path_list in self.path_dict.items()}\n",
    "\n",
    "        self.label_list = list(self.path_dict.keys())\n",
    "\n",
    "        self.sample_num = sample_num\n",
    "        self.train_transform = train_transform\n",
    "        self.valid_transform = valid_transform\n",
    "\n",
    "        self.losses = []\n",
    "\n",
    "    def get_data_set(self):\n",
    "        _item_list =  sum(self.selected_items.values(), [])\n",
    "        random.shuffle(_item_list)\n",
    "\n",
    "        train_index_set, valid_index_set = train_test_split(\n",
    "            _item_list,\n",
    "            test_size=config.test_size,\n",
    "            stratify=sum([[_label] * len(_path_list) for _label, _path_list in self.selected_items.items()], []),\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        self.train_set = custom_dataset(train_index_set, self.label_list, self.train_transform)\n",
    "        self.valid_set = custom_dataset(valid_index_set, self.label_list, self.valid_transform)\n",
    "\n",
    "        print(f'Train set: {Counter(self.train_set.labels)}')\n",
    "        print(f'Valid set: {Counter(self.valid_set.labels)}')\n",
    "\n",
    "        return self.train_set, self.valid_set\n",
    "    \n",
    "    def get_data_loader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train_set, pin_memory=True, \n",
    "            batch_sampler=StratifiedBatchSampler(\n",
    "                [self.label_list.index(_label) for _label in self.train_set.labels], \n",
    "                batch_size=config.batch_size\n",
    "            )\n",
    "        )\n",
    "\n",
    "        valid_loader = DataLoader(\n",
    "            self.valid_set, pin_memory=True,\n",
    "            batch_sampler=StratifiedBatchSampler(\n",
    "                [self.label_list.index(_label) for _label in self.valid_set.labels], \n",
    "                batch_size=config.batch_size\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return train_loader, valid_loader\n",
    "    \n",
    "    def collect_losses(self, _paths, _labels, _losses):\n",
    "        for _path, _label, _loss in zip(_paths, _labels, _losses):\n",
    "            self.losses.append((_path, _label.item(), _loss.item()))\n",
    "\n",
    "    def renew_data_loader(self, resample_ratio):\n",
    "        selected_items_dict = {}\n",
    "        for _path, _label, _loss in self.losses:\n",
    "            _label = self.label_list[_label]\n",
    "            if selected_items_dict.get(_label) == None:\n",
    "                selected_items_dict[_label] = []\n",
    "\n",
    "            selected_items_dict[_label].append((_path, _loss))\n",
    "        \n",
    "        selected_items = {}\n",
    "        for _label, _path_list in selected_items_dict.items():\n",
    "            _paths, _weights = zip(*_path_list)\n",
    "            _weights = [(_weight - min(_weights))/(max(_weights)-min(_weights)) for _weight in _weights]\n",
    "\n",
    "            selected_items[_label] = random.choices(_paths,\n",
    "                                                    k=int(self.sample_num * (1-resample_ratio)),\n",
    "                                                    weights=_weights)\n",
    "        \n",
    "        unselected_items = {_label: random.sample([_path for _path in _path_list if _path not in selected_items_dict[_label]],\n",
    "                                                  k=int(self.sample_num * resample_ratio)) for _label, _path_list in self.path_dict.items()}\n",
    "\n",
    "        self.selected_items = {}\n",
    "        for (_label, _selected_path_list), (_label, _unselected_path_list) in zip(selected_items.items(), unselected_items.items()):\n",
    "            self.selected_items[_label] = []\n",
    "            self.selected_items[_label].extend(_selected_path_list)\n",
    "            # print(f'{_label}-selected: {len(_selected_path_list)}')\n",
    "            self.selected_items[_label].extend(_unselected_path_list)\n",
    "            # print(f'{_label}-unselected: {len(_unselected_path_list)}')\n",
    "            # print()\n",
    "\n",
    "        self.losses = []\n",
    "\n",
    "        self.get_data_set()\n",
    "\n",
    "        return self.get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "237a143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factory = custom_data_factory(item_list, config.sample_num, train_transform, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce3b0c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andesite',\n",
       " 'Basalt',\n",
       " 'Etc',\n",
       " 'Gneiss',\n",
       " 'Granite',\n",
       " 'Mud_Sandstone',\n",
       " 'Weathered_Rock']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_factory.label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bff4f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andesite: 8000\n",
      "Basalt: 8000\n",
      "Etc: 8000\n",
      "Gneiss: 8000\n",
      "Granite: 8000\n",
      "Mud_Sandstone: 8000\n",
      "Weathered_Rock: 8000\n"
     ]
    }
   ],
   "source": [
    "for label, selected_items in data_factory.selected_items.items():\n",
    "    print(f'{label}: {len(selected_items)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c72917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = [(path, os.path.basename(os.path.dirname(path))) for path in item_list]\n",
    "# _, labels = zip(*paths)\n",
    "\n",
    "# train_index_set, valid_index_set = train_test_split(\n",
    "#     paths,\n",
    "#     test_size=config.test_size,\n",
    "#     stratify=labels,\n",
    "#     shuffle=True,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55746e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = list(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "225d30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = custom_dataset(train_index_set, label_list, train_transform)\n",
    "# valid_set = custom_dataset(valid_index_set, label_list, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88914bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_set))\n",
    "# print(len(valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20280f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(\n",
    "#     train_set, pin_memory=True, \n",
    "#     batch_sampler=StratifiedBatchSampler(\n",
    "#         [label_list.index(_label) for _label in train_set.labels], \n",
    "#         batch_size=config.batch_size\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# valid_loader = DataLoader(\n",
    "#     valid_set, pin_memory=True,\n",
    "#     batch_sampler=StratifiedBatchSampler(\n",
    "#         [label_list.index(_label) for _label in valid_set.labels], \n",
    "#         batch_size=config.batch_size\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a90bdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_loader))\n",
    "# print(len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eda8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=config.epoch//3,\n",
    "    T_mult=3,\n",
    "    eta_min=config.lr / 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5369a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(features_dict, epoch):\n",
    "    os.makedirs(config.visualize_save_dir, exist_ok=True)\n",
    "\n",
    "    all_features = np.concatenate([np.array(value) for label_name, value in features_dict.items()], axis=0)\n",
    "    labels = sum([[label_name] * len(value) for label_name, value in features_dict.items()], [])\n",
    "    \n",
    "    n_samples = len(all_features)\n",
    "    perplexity = min(30, n_samples - 1)\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "    features_2d = tsne.fit_transform(all_features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], \n",
    "                    hue=labels)\n",
    "    \n",
    "    plt.title(f'Feature Space Visualization (t-SNE)\\nSamples: {n_samples}, Perplexity: {perplexity}')\n",
    "    plt.savefig(os.path.join(config.visualize_save_dir, f'feature_space_{epoch}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Visualization completed successfully\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c6967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, epoch, valid_loader):\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    features_dict = {label:[] for label in data_factory.label_list}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in tqdm(valid_loader, desc=f'Validating', leave=False):\n",
    "            images, labels = images[0].to(config.device), labels.to(config.device)\n",
    "            \n",
    "            outputs, features = model(images, return_features=True)\n",
    "\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            features_np = features.cpu().numpy()\n",
    "            labels_np = labels.cpu().numpy()\n",
    "\n",
    "            for feat, label in zip(features_np, labels_np):\n",
    "                features_dict[data_factory.label_list[label]].append(feat)\n",
    "\n",
    "            all_probs.append(probs.cpu().numpy().flatten())\n",
    "            all_labels.append(labels_np)\n",
    "    \n",
    "    if epoch % config.visualize_epoch == 0:\n",
    "        visualize_features(features_dict, epoch)\n",
    "        \n",
    "    all_probs_roc = np.array(all_probs).reshape(-1, len(data_factory.label_list))\n",
    "    all_probs = np.array([np.argmax(_pred) for _pred in all_probs_roc])\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(all_labels, all_probs),\n",
    "        'precision': precision_score(all_labels, all_probs, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_probs, average='weighted', zero_division=0),\n",
    "        'f1': f1_score(all_labels, all_probs, average='weighted', zero_division=0),\n",
    "        'roc_auc':roc_auc_score(all_labels, all_probs_roc, multi_class='ovr'),\n",
    "        'confusion_matrix': confusion_matrix(all_labels, all_probs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40116b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, start_epoch=0):\n",
    "    train_history = {}\n",
    "\n",
    "    contrastive_criterion = NTXentLoss()\n",
    "    normal_criterion = FocalLoss()\n",
    "\n",
    "    best_score = -1.0\n",
    "\n",
    "    data_factory.get_data_set()\n",
    "    train_loader, valid_loader = data_factory.get_data_loader()\n",
    "\n",
    "    for epoch in range(config.epoch):\n",
    "        if epoch < start_epoch:\n",
    "            continue\n",
    "\n",
    "        model.train()\n",
    "        total_losses = 0.0\n",
    "        \n",
    "        if epoch < config.epoch // 3:\n",
    "            for images, labels, paths in tqdm(train_loader, desc=f'Training epoch: {epoch+1}/{config.epoch}'):\n",
    "                image_1, image_2 = images[0].to(config.device), images[1].to(config.device)\n",
    "                labels = labels.to(config.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                z_1 = model.forward_features(image_1)\n",
    "                z_2 = model.forward_features(image_2)\n",
    "\n",
    "                loss = contrastive_criterion(z_1, z_2, labels)\n",
    "                \n",
    "                loss.mean().backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_losses += loss.mean().item()\n",
    "                scheduler.step()\n",
    "\n",
    "                data_factory.collect_losses(paths, labels.cpu(), loss.cpu())\n",
    "\n",
    "        else:\n",
    "            if epoch < config.epoch // 3 + 7:\n",
    "                for param in model.backbone.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            for images, labels, paths in tqdm(train_loader, desc=f'Training epoch: {epoch+1}/{config.epoch}', leave=False):\n",
    "                images = images[0].to(config.device)\n",
    "                labels = labels.to(config.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(images)\n",
    "                \n",
    "                loss = normal_criterion(outputs, labels)\n",
    "                \n",
    "                loss.mean().backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_losses += loss.mean().item()\n",
    "                scheduler.step()\n",
    "                \n",
    "                data_factory.collect_losses(paths, labels.cpu(), loss.cpu())\n",
    "\n",
    "        valid_results = evaluate(model, epoch, valid_loader=valid_loader)\n",
    "        if best_score < valid_results['f1']:\n",
    "            best_score = valid_results['f1']\n",
    "            torch.save(model, 'best_model.pt')\n",
    "\n",
    "        print(f\"epoch {epoch+1:>3d}\", end='/')\n",
    "        print(f\"accuracy: {valid_results['accuracy']}\", end=' / ')\n",
    "        print(f\"precision: {valid_results['precision']}\", end=' / ')\n",
    "        print(f\"recall: {valid_results['recall']}\", end=' / ')\n",
    "        print(f\"f1: {valid_results['f1']}\", end=' / ')\n",
    "        print(f\"roc_auc: {valid_results['roc_auc']}\")\n",
    "        print(f\"{valid_results['confusion_matrix']}\")\n",
    "\n",
    "        train_history[epoch] = valid_results\n",
    "\n",
    "        print(\"renew data_loader\") \n",
    "        train_loader, valid_loader = data_factory.renew_data_loader(resample_ratio=0.7)\n",
    "        for label, selected_items in data_factory.selected_items.items():\n",
    "            print(f'{label}: {len(selected_items)}', end='\\n')\n",
    "        print()\n",
    "        \n",
    "    with open(os.path.join(os.getcwd(), 'train_history.json'), 'w', encoding='utf-8-sig') as json_file:\n",
    "        json.dump(train_history, json_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aeeeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_noSSL(model):\n",
    "    train_history = {}\n",
    "\n",
    "    contrastive_criterion = NTXentLoss()\n",
    "    normal_criterion = FocalLoss()\n",
    "\n",
    "    best_score = -1.0\n",
    "\n",
    "    data_factory.get_data_set()\n",
    "    train_loader, valid_loader = data_factory.get_data_loader()\n",
    "\n",
    "    for epoch in range(config.epoch):\n",
    "        model.train()\n",
    "        total_losses = 0.0\n",
    "        \n",
    "        for images, labels, paths in tqdm(train_loader, desc=f'Training epoch: {epoch+1}/{config.epoch}', leave=False):\n",
    "            images = images[0].to(config.device)\n",
    "            labels = labels.to(config.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = normal_criterion(outputs, labels)\n",
    "            \n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_losses += loss.mean().item()\n",
    "            scheduler.step()\n",
    "            \n",
    "            data_factory.collect_losses(paths, labels.cpu(), loss.cpu())\n",
    "\n",
    "        valid_results = evaluate(model, epoch, valid_loader=valid_loader)\n",
    "        if best_score < valid_results['f1']:\n",
    "            best_score = valid_results['f1']\n",
    "            torch.save(model, 'best_model.pt')\n",
    "\n",
    "        print(f\"epoch {epoch+1:>3d}\", end='/')\n",
    "        print(f\"accuracy: {valid_results['accuracy']}\", end=' / ')\n",
    "        print(f\"precision: {valid_results['precision']}\", end=' / ')\n",
    "        print(f\"recall: {valid_results['recall']}\", end=' / ')\n",
    "        print(f\"f1: {valid_results['f1']}\", end=' / ')\n",
    "        print(f\"roc_auc: {valid_results['roc_auc']}\")\n",
    "        print(f\"{valid_results['confusion_matrix']}\")\n",
    "\n",
    "        train_history[epoch] = valid_results\n",
    "\n",
    "        print(\"renew data_loader\")\n",
    "        train_loader, valid_loader = data_factory.renew_data_loader(resample_ratio=0.7)\n",
    "        for label, selected_items in data_factory.selected_items.items():\n",
    "            print(f'{label}: {len(selected_items)}', end='\\n')\n",
    "        print()\n",
    "        \n",
    "    with open(os.path.join(os.getcwd(), 'train_history.json'), 'w', encoding='utf-8-sig') as json_file:\n",
    "        json.dump(train_history, json_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d43254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Counter({'Weathered_Rock': 6482, 'Andesite': 6471, 'Gneiss': 6399, 'Mud_Sandstone': 6389, 'Granite': 6366, 'Basalt': 6360, 'Etc': 6333})\n",
      "Valid set: Counter({'Etc': 1667, 'Basalt': 1640, 'Granite': 1634, 'Mud_Sandstone': 1611, 'Gneiss': 1601, 'Andesite': 1529, 'Weathered_Rock': 1518})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/60:   2%|▏         | 19/1245 [12:04:29<1321:07:15, 3879.31s/it]"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('best_model.pt', weights_only=True))\n",
    "# model = torch.load('best_model.pt', weights_only=False)\n",
    "model = model.to(config.device)\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b75af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33mtrain_history.json\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8-sig\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     json.dump(\u001b[43mtrain_history\u001b[49m, json_file, indent=\u001b[32m2\u001b[39m, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_history' is not defined"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(os.getcwd(), 'train_history.json'), 'w', encoding='utf-8-sig') as json_file:\n",
    "    json.dump(train_history, json_file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a44e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d48f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403911d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b962396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608bc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
